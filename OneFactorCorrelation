#install necessary packages
install.packages("googleAnalyticsR", dependencies=TRUE)
install.packages("stringr")
install.packages("dplyr")
install.packages("plyr")

#load necessary libraries
library(googleAnalyticsR)
library(stringr)
library(dplyr)
library(plyr)

#authorizes R to establish a connection with our GA account
ga_auth()

#brand view ID
ga_id <- 186738676

#test query
google_analytics(ga_id, 
                 date_range = c("2019-12-01", "2020-01-01"), 
                 metrics = "sessions", 
                 dimensions = c("year","month","hostname"))

test <- ga_filter_view_list(1341196, "UA-1341196-19", 186738676)

#create a dataframe that contains all the segments IDs that we will be pulling
all.segments <- as.data.frame(ga_segment_list())

hev.segments.allfields <- subset(all.segments,grepl("HEV",name))

hev.segments <- select(hev.segments.allfields,id,segmentId,name)

#test query with segment and unsampled data
test <- segment_ga4("FCA 2020 HEV 4x4  Story module clicks", segment_id = "gaid::nfqCa3bSQGWRCsIAksdv3w")

test_segment <- google_analytics(ga_id, 
                                   date_range = c("2019-12-01", "2020-01-01"), 
                                   metrics = "sessions", 
                                   dimensions = c("year","month","hostname"),
                                   segments = test,
                                   filtersExpression = "ga:hostname==www.jeep.ca",
                                   anti_sample = TRUE)

#start querying the GA reporting API against all hev segments by brand, so that we can look at one to one correlation first

list.sessions <- list()
list.year <- list()
list.month <- list()
list.segmentname <- list()
list.hevnames <- list()

#jeep query
i=1
#after testing, change 1:3 to 1:nrow(hev.segments)
for (i in 1:3){
  segmentdata <- google_analytics(ga_id, 
                           date_range = c("2019-01-01", "2020-02-29"), 
                           metrics = "sessions", 
                           dimensions = c("year","month"),
                           segments = segment_ga4(hev.segments$name[i], segment_id = hev.segments$segmentId[i]),
                           filtersExpression = "ga:hostname==www.jeep.ca",
                           anti_sample = TRUE)
  
    #segmentnum <- paste0("jeep","hevsegment", i)
    segmentdata <- as.data.frame(segmentdata)
    
    segmentsessions <- segmentdata$sessions
    segmentyear <- segmentdata$year
    segmentmonth <- segmentdata$month
    segmentname <- segmentdata$segment

    list.sessions <- append(list.sessions,segmentsessions)
    list.year <- append(list.year,segmentyear)
    list.month <- append(list.month,segmentmonth)
    list.segmentname <- append(list.segmentname,segmentname)
    list.hevnames <- append(list.hevnames,segmentnum)
    
  i = i+1
}

list.sessions <- do.call(rbind, list.sessions)
colnames(list.sessions) <- c("sessions")

list.year <- do.call(rbind, list.year)
colnames(list.year) <- c("year")

list.month <- do.call(rbind, list.month)
colnames(list.month) <- c("month")

list.segmentname <- do.call(rbind, list.segmentname)
colnames(list.segmentname) <- c("segmentname")

#bind all of our columns together
jeephevdata <- data.frame(list.segmentname,list.year,list.month,list.sessions)


#for each hev segment, calculate some basic statistics (min, max, average, variance, 
#number of data points, number of extreme outliers, shapiro wilk statistic)
#pearson correlation coefficient has the following assumptions: 
#normality of variables, linearity, and homoscedasticity
#to test the normality of our hev segments, we will use the shapiro wilk test

jeepmean <- aggregate( sessions ~ segmentname, jeephevdata, mean )
jeepmax <- aggregate( sessions ~ segmentname, jeephevdata, max )
jeepmin <- aggregate( sessions ~ segmentname, jeephevdata, min )
jeepvariance <- aggregate( sessions ~ segmentname, jeephevdata, var )
jeepcount <- aggregate( sessions ~ segmentname, jeephevdata, length )


#make a function that defines the lower bound for an outlier
jeepoutlierlowerbound <- function(x){
  quantile(x, 0.25)*1.5
}
jeepoutlierlowerbound <- aggregate( sessions ~ segmentname, jeephevdata, jeepoutlierlowerbound )
names(jeepoutlierlowerbound)[2] <- "lowerbound"


#make a function that defines the upper bound for an outlier
jeepoutlierupperbound <- function(x){
  quantile(x, 0.75)*1.5
}
jeepoutlierupperbound <- aggregate( sessions ~ segmentname, jeephevdata, jeepoutlierupperbound )
names(jeepoutlierupperbound)[2] <- "upperbound"


#now left join these upper and lower bounds to our main dataset so that we can flag which values fall above and below the bounds
jeephevdata <-merge(x=jeephevdata,y=jeepoutlierupperbound,by="segmentname",all.x=TRUE)
jeephevdata <-merge(x=jeephevdata,y=jeepoutlierlowerbound,by="segmentname",all.x=TRUE)


#make a function to flag data points that are lower than the lower bound
#make sessions the x value and the lower bound the y value

#lower bound flag
lowerbound.function <- function(x,y){
  ifelse(x<y,1,0)
}

lowerflags <- data.frame(mapply(lowerbound.function,jeephevdata$sessions,jeephevdata$lowerbound))
names(lowerflags)[1] <- "lowerboundflag"

#bind our lowerbound flags to the original dataframe
jeephevdata <- cbind(jeephevdata,lowerflags)


#do the same thing for the upper bound now
#make sessions the x value and the upper bound the y value

#upper bound flag
upperbound.function <- function(x,y){
  ifelse(x>y,1,0)
}

upperflags <- data.frame(mapply(upperbound.function,jeephevdata$sessions,jeephevdata$upperbound))
names(upperflags)[1] <- "upperboundflag"

#bind our upperbound flags to the original dataframe
jeephevdata <- cbind(jeephevdata,upperflags)


#now that we have both upper and lower bound flags, count the number of flags ie. the number of upper and lower outliers we have
jeepupperoutliers <- aggregate( upperboundflag ~ segmentname, jeephevdata, sum )
jeeploweroutliers <- aggregate( lowerboundflag ~ segmentname, jeephevdata, sum )

#define function for shapiro wilk statistic
jeepshapiro <- function(x){
  shapiro <- shapiro.test(x)
  #this returns the p-value of the shapiro wilk test
  return(shapiro[[2]])
}
jeepshapiro <- aggregate( sessions ~ segmentname, jeephevdata, jeepshapiro )


#check to make sure that we've calculated our parameters for all of our segments
stopifnot(length(jeepmean)==length(jeepmax))
stopifnot(length(jeepmean)==length(jeepmin))
stopifnot(length(jeepmean)==length(jeepvariance))
stopifnot(length(jeepmean)==length(jeepcount))
stopifnot(length(jeepmean)==length(jeepoutlierlowerbound))
stopifnot(length(jeepmean)==length(jeepoutlierupperbound))
stopifnot(length(jeepmean)==length(jeepshapiro))
stopifnot(length(jeepmean)==length(jeepupperoutliers))
stopifnot(length(jeepmean)==length(jeeploweroutliers))

#before merging all our summary stat dataframes together, we will rename the columns accordingly
names(jeepmean)[2] <- "mean"
names(jeepmax)[2] <- "max"
names(jeepmin)[2] <- "min"
names(jeepvariance)[2] <- "variance"
names(jeepcount)[2] <- "count"
names(jeepshapiro)[2] <- "shapiro"
names(jeepupperoutliers)[2] <- "upperoutliers"
names(jeeploweroutliers)[2] <- "loweroutliers"



#now that we've calculated all our summary statistics, let's compile them into one dataframe
jeep.summarystats <- merge(jeepmean,jeepmax,by="segmentname")
jeep.summarystats <- merge(jeep.summarystats,jeepmin,by="segmentname")
jeep.summarystats <- merge(jeep.summarystats,jeepvariance,by="segmentname")
jeep.summarystats <- merge(jeep.summarystats,jeepcount,by="segmentname")
jeep.summarystats <- merge(jeep.summarystats,jeepshapiro,by="segmentname")
jeep.summarystats <- merge(jeep.summarystats,jeepupperoutliers,by="segmentname")
jeep.summarystats <- merge(jeep.summarystats,jeeploweroutliers,by="segmentname")

#export summary statistics for each of our segments as an excel so that the team can determine 
#which should be included or excluded for further analysis
write.csv(jeep.summarystats, file = "Desktop/segmentsummarystats.csv")
